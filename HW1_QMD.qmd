---
title: "new_quarto_for_try"
author: "Zehra Cebeci, Ömer Faruk Yahşi"
format: html
editor: visual
---

## Homework 1

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## **Housing in Luxembourg**

We are going to download data about house prices in Luxembourg. Luxembourg is a little Western European country the author hails from that looks like a shoe and is about the size of .98 Rhode Islands.

![](https://raps-with-r.dev/images/lux_rhode_island.png)

In this project our goal is to:

-   Get data trapped inside an Excel file into a neat data frame;

-   Convert nominal to real prices using a simple method;

-   Make some tables and plots and call it a day (for now).

## **Saving trapped data from Excel**

The picture below shows an Excel file made for human consumption:

![](https://raps-with-r.dev/images/obs_hab_xlsx_overview.png)

So why is this file not machine-readable? Here are some issues:

-   The table does not start in the top-left corner of the spreadsheet, which is where most importing tools expect it to be;

-   The spreadsheet starts with a header that contains an image and some text;

-   Numbers are text and use "," as the thousands separator;

-   You don't see it in the screenshot, but each year is in a separate sheet.

So first, let's load some packages:

```{r}
library(dplyr)
library(purrr)
library(readxl)
library(stringr)
library(janitor)
```

Next, the code below downloads the data, and puts it in a data frame:

```{r}
# The url below points to an Excel file
# hosted on the book’s github repository
url <- "https://is.gd/1vvBAc"

raw_data <- tempfile(fileext = ".xlsx")

download.file(url, raw_data,
              method = "auto",
              mode = "wb")

sheets <- excel_sheets(raw_data)

read_clean <- function(..., sheet){
  read_excel(..., sheet = sheet) |>
    mutate(year = sheet)
}

raw_data <- map(
  sheets,
  ~read_clean(raw_data,
              skip = 10,
              sheet = .)
                   ) |>
  bind_rows() |>
  clean_names()

raw_data <- raw_data |>
  rename(
    locality = commune,
    n_offers = nombre_doffres,
    average_price_nominal_euros = prix_moyen_annonce_en_courant,
    average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant,
    average_price_m2_nominal_euros = prix_moyen_annonce_au_m2_en_courant
  ) |>
  mutate(locality = str_trim(locality)) |>
  select(year, locality, n_offers, starts_with("average"))
```

Running this code results in a neat data set:

```{r}
raw_data
```

But there's a problem: columns that should be of type numeric are of type character instead (`average_price_nominal_euros` and `average_price_m2_nominal_euros`). There's also another issue, which you would eventually catch as you'll explore the data: the naming of the communes is not consistent. Let's take a look:

```{r}
raw_data |>
  filter(grepl("Luxembourg", locality)) |>
  count(locality)
```

We can see that the city of Luxembourg is spelled in two different ways. It's the same with another commune, Pétange:

```{r}
raw_data |>
  filter(grepl("P.tange", locality)) |>
  count(locality)
```

So sometimes it is spelled correctly, with an "é", sometimes not. Let's write some code to correct both these issues:

```{r}
raw_data <- raw_data |>
  mutate(
    locality = ifelse(grepl("Luxembourg-Ville", locality),
                      "Luxembourg",
                      locality),
         locality = ifelse(grepl("P.tange", locality),
                           "Pétange",
                           locality)
         ) |>
  mutate(across(starts_with("average"),
         as.numeric))
```

Now this is interesting -- converting the `average` columns to numeric resulted in some `NA` values. Let's see what happened:

```{r}
raw_data |>
  filter(is.na(average_price_nominal_euros))
```

It turns out that there are no prices for certain communes, but that we also have some rows with garbage in there. Let's go back to the raw data to see what this is about:

![](https://raps-with-r.dev/images/obs_hab_xlsx_missing.png)

So it turns out that there are some rows that we need to remove. We can start by removing rows where `locality` is missing. Then we have a row where `locality` is equal to "Total d'offres".

Let's first remove the rows stating the sources:

```{r}
raw_data <- raw_data |>
  filter(!grepl("Source", locality))
```

Let's now only keep the communes in our data:

```{r}
commune_level_data <- raw_data |>
    filter(!grepl("nationale|offres", locality),
           !is.na(locality))
```

And let's create a dataset with the national data as well:

```{r}
country_level <- raw_data |>
  filter(grepl("nationale", locality)) |>
  select(-n_offers)

offers_country <- raw_data |>
  filter(grepl("Total d.offres", locality)) |>
  select(year, n_offers)

country_level_data <- full_join(country_level, offers_country) |>
  select(year, locality, n_offers, everything()) |>
  mutate(locality = "Grand-Duchy of Luxembourg")
```

Now the data looks clean, and we can start the actual analysis... or can we? Before proceeding, it would be nice to make sure that we got every commune in there. For this, we need a list of communes from Luxembourg. [Thankfully, Wikipedia has such a list](https://en.wikipedia.org/wiki/List_of_communes_of_Luxembourg)[6](https://raps-with-r.dev/project_start.html#fn6).

So let's scrape and save this list:

```{r}
current_communes <- "https://is.gd/lux_communes" |>
  rvest::read_html() |>
  rvest::html_table() |>
  purrr::pluck(2) |>
  janitor::clean_names() |>
  dplyr::filter(name_2 != "Name") |>
  dplyr::rename(commune = name_2) |>
  dplyr::mutate(commune = stringr::str_remove(commune, " .$"))
```

Let's see if we have all the communes in our data:

```{r}
setdiff(unique(commune_level_data$locality),
        current_communes$commune)
```

We see many communes that are in our `commune_level_data`, but not in `current_communes`. There's one obvious reason: differences in spelling, for example, "Kaerjeng" in our data, but "Käerjeng" in the table from Wikipedia. 

Here again, we can use a list from Wikipedia, and here again, I decide to re-host it on Github pages to avoid problems in the future:

```{r}
former_communes <- "https://is.gd/lux_former_communes" |>
  rvest::read_html() |>
  rvest::html_table() |>
  purrr::pluck(3) |>
  janitor::clean_names() |>
  dplyr::filter(year_dissolved > 2009)

former_communes
```

As you can see, since 2010 many communes have merged to form new ones. We can now combine the list of current and former communes, as well as harmonise their names:

```{r}
communes <- unique(c(former_communes$name,
                     current_communes$commune))
# we need to rename some communes

# Different spelling of these communes between wikipedia and the data

communes[which(communes == "Clemency")] <- "Clémency"
communes[which(communes == "Redange")] <- "Redange-sur-Attert"
communes[which(communes == "Erpeldange-sur-Sûre")] <- "Erpeldange"
communes[which(communes == "Luxembourg City")] <- "Luxembourg"
communes[which(communes == "Käerjeng")] <- "Kaerjeng"
communes[which(communes == "Petange")] <- "Pétange"
```

Let's run our test again:

```{r}
setdiff(unique(commune_level_data$locality),
        communes)
```

Great! When we compare the communes that are in our data with every commune that has existed since 2010, we don't have any commune that is unaccounted for.

```{r}
head(commune_level_data)
```

## **Analysing the data**

```{r}
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)

#Let's load the datasets:

commune_level_data <- read.csv("datasets/commune_level_data.csv")
country_level_data <- read.csv("datasets/country_level_data.csv")

#Let's compute the Laspeyeres index for each commune:

commune_level_data <- commune_level_data %>%
  group_by(locality) %>%
  mutate(p0 = ifelse(year == "2010", average_price_nominal_euros, NA)) %>%
  fill(p0, .direction = "down") %>%
  mutate(p0_m2 = ifelse(year == "2010", average_price_m2_nominal_euros, NA)) %>%
  fill(p0_m2, .direction = "down") %>%
  ungroup() %>%
  mutate(pl = average_price_nominal_euros/p0*100,
         pl_m2 = average_price_m2_nominal_euros/p0_m2*100)


#Let's also compute it for the whole country:

country_level_data <- country_level_data %>%
  mutate(p0 = ifelse(year == "2010", average_price_nominal_euros, NA)) %>%
  fill(p0, .direction = "down") %>%
  mutate(p0_m2 = ifelse(year == "2010", average_price_m2_nominal_euros, NA)) %>%
  fill(p0_m2, .direction = "down") %>%
  mutate(pl = average_price_nominal_euros/p0*100,
         pl_m2 = average_price_m2_nominal_euros/p0_m2*100)

#Let's compute the rate of cahnge in price on the percentage scale for each commune:

commune_level_data <- commune_level_data %>%
  group_by(locality) %>%
  mutate(p0 = ifelse(year == "2010", average_price_nominal_euros, NA)) %>%
  fill(p0, .direction = "down") %>%
  mutate(p0_m2 = ifelse(year == "2010", average_price_m2_nominal_euros, NA)) %>%
  fill(p0_m2, .direction = "down") %>%
  ungroup() %>%
  mutate(pl_in_perc = ((average_price_nominal_euros-p0)/p0)*100,
         pl_m2_in_perc = ((average_price_m2_nominal_euros-p0_m2)/p0_m2)*100)

#Let's also compute it for the whole country:

country_level_data <- country_level_data %>%
  mutate(p0 = ifelse(year == "2010", average_price_nominal_euros, NA)) %>%
  fill(p0, .direction = "down") %>%
  mutate(p0_m2 = ifelse(year == "2010", average_price_m2_nominal_euros, NA)) %>%
  fill(p0_m2, .direction = "down") %>%
  mutate(pl_in_perc = ((average_price_nominal_euros-p0)/p0)*100,
         pl_m2_in_perc = ((average_price_m2_nominal_euros-p0_m2)/p0_m2)*100)
```

```{r}

#We are going to create a plot for 5 communes and compare the price evolution in the communes
#to the national price evolution. Let's first list the communes:

communes <- c("Luxembourg",
              "Esch-sur-Alzette",
              "Mamer",
              "Schengen",
              "Wincrange")

filtered_data <- commune_level_data %>% filter(locality %in% communes)

# Create the line plot
ggplot(filtered_data, aes(x = year, y = pl_m2, color = locality, group = locality)) +
  geom_line() +
  labs(title = "House Price per Square Meter for Selected Communes",
       x = "Year",
       y = "House Price per Square Meter") +
  scale_color_brewer(palette = "Set1") + # Adjust color palette as needed
  scale_x_continuous(breaks = seq(2010, 2020, by = 2)) + # Set the x-axis breaks
  scale_y_continuous(breaks = seq(0, 250, by = 20))  # Set the x-axis breaks
```

bar charts all in one graph without subplot

```{r}
# Create a grouped bar chart for house price per square meter variation
ggplot(filtered_data, aes(x = year, y = pl_m2_in_perc, fill = locality)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "House Price per Square Meter Variation by Year for Selected Communes",
       x = "Year",
       y = "House Price per Square Meter") +
  scale_x_continuous(breaks = seq(2010, 2020, by = 2)) + # Set the x-axis 
  scale_y_continuous(limits = c(0, 150), breaks = seq(0, 150, by = 15)) +
  theme_minimal() 

```

each bar chart in the individual plots

```{r}
ggplot(filtered_data, aes(x = year, y = pl_m2_in_perc, fill = as.factor(locality))) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(locality ~ ., scales = "free_y") +
  labs(
    title = "HP per Square Meter % Variation by Year with respect to 2010 prices",
    x = "Year",
    y = "House Price per Square Meter variation in % wrt 2010",
    fill = "Communes"  # Change the title for the fill legend

  ) +
  scale_x_continuous(breaks = seq(2010, 2020, by = 1)) +
  #scale_y_continuous(limits = c(0, 150), breaks = seq(0, 150, by = 15)) +
  scale_fill_brewer(palette = "Set1") +  # Change color palette, adjust as needed
  theme_minimal() +
  theme(legend.position = "right", panel.spacing = unit(0.5, "lines")) +
  theme(legend.position = "right",
        strip.text.y = element_blank())  # Removes the facet strip text

```
